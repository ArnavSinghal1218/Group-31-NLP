# -*- coding: utf-8 -*-
"""Untitled24.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/18tn-oyzb_KYjiuoDlCtbN9GSL9xfUzpf
"""

import requests
import json
import xml.etree.ElementTree as ET
import time
from tqdm import tqdm
import multiprocessing
from multiprocessing import Pool, Manager




def get_abstract(id, failure_time=0):
    base_url = 'https://eutils.ncbi.nlm.nih.gov/entrez/eutils/efetch.fcgi'
    url = f'{base_url}?db=pubmed&id={id}&retmode=xml'
    headers = {
        'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/58.0.3029.110 Safari/537.3'}
    try:
        response = requests.get(url,headers=headers)

        data = ET.fromstring(response.text)
        abstract_texts = [''.join(abstract_text.itertext()).strip() for abstract_text in
                          data.findall('.//AbstractText')]
        # title_elements = data.findall('.//Title')
        if abstract_texts:
            abstract = '\n'.join(abstract_texts)
            lastname = data.findall('.//LastName')
            forename = data.findall('.//ForeName')
            author = [[lastname[i].text + ' ' + forename[i].text] for i in range(len(lastname))]
            #print(author)
            title = data.findall('.//ArticleTitle')[0].text
            #articleid = [[i.text] for i in data.findall('.//ArticleId')]
            #articleid = [[i.text] for i in data.findall('.//ArticleId') if i.find('ReferenceList') is None]

            article_ids_in_articleidlist = data.findall('.//ArticleId')

            # Find all ArticleId tags in ReferenceList
            article_ids_in_referencelist = data.find('.//ReferenceList')
            if(article_ids_in_referencelist):
                filter = article_ids_in_referencelist.findall('.//ArticleId')
                articleid = [
                    [article_id.text] for article_id in article_ids_in_articleidlist
                    if article_id not in filter
                ]
            else:
                articleid = [
                    [article_id.text] for article_id in article_ids_in_articleidlist
                ]

            return abstract,author,url,title,articleid
        else:
            #print("aaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaa\n")
            return None,None,None,None,None
    except:

        #print(f'###{url}### : retrival failed : {failure_time + 1}\n', flush=True)
        if (failure_time < 2):  # maximum try of 3 times
            time.sleep(1.0)
            return get_abstract(id, failure_time + 1)
        else:
            #print(f'###{id}###: failed 3 times, abandoning \n')
            return None,None,None,None,None

        # return None


def get_abstract_multiproc(proc_num, total_process, lock, lists, lists_author, lists_url, lists_title, _article_ids, lists_failed,lists_aid):
    #proc_num, total_process, lock, lists, _article_ids = args_tuple
    #print("process" + str(proc_num) + "\n")
    article_num = len(_article_ids)
    current_proc_num = proc_num

    while (current_proc_num < article_num):
        #print(current_proc_num)
        abstract,author,url,title,aid = get_abstract(_article_ids[current_proc_num])
        if(abstract != None):
            print(f'###Thread:{current_proc_num} complete!###', flush=True)
            with lock:
                lists.append(abstract)
                lists_author.append(author)
                lists_url.append(url)
                lists_title.append(title)
                lists_aid.append(aid)
        else:
            print(f'###Thread:{current_proc_num} failed! id:{_article_ids[current_proc_num]}###', flush=True)
            lists_failed.append(_article_ids[current_proc_num])
        current_proc_num += total_process
        time.sleep(0.5)