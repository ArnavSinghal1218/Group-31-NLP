{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "OYFLxdJ979TZ"
      },
      "outputs": [],
      "source": [
        "import requests\n",
        "from xml.etree import ElementTree\n",
        "\n",
        "import pandas as pd\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "\n",
        "from torchtext.datasets import UDPOS\n",
        "\n",
        "import numpy as np\n",
        "import math\n",
        "\n",
        "import time\n",
        "import random\n",
        "from torchtext.vocab import build_vocab_from_iterator\n",
        "from torch.utils.data import Dataset, DataLoader\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "tzA4Ea2G4rjF"
      },
      "outputs": [],
      "source": [
        "# Initialize the dataset\n",
        "pub_med = []\n",
        "num_articles = 10000 # want as many as there are with the correct information\n",
        "\n",
        "# Use ESearch to get PMIDs\n",
        "esearch_url = \"https://eutils.ncbi.nlm.nih.gov/entrez/eutils/esearch.fcgi\"\n",
        "search_params = {\n",
        "    'db': 'pubmed',\n",
        "    'term': 'intelligence[Abstract] AND (\"2013/01/01\"[Date - Publication] : \"2023/12/31\"[Date - Publication])',\n",
        "    'retmax': num_articles, # is by default 20\n",
        "    'retmode': 'json',\n",
        "\n",
        "}\n",
        "\n",
        "# send request to eSearch, and process response\n",
        "search_response = requests.get(esearch_url, params=search_params)\n",
        "search_data = search_response.json()['esearchresult']\n",
        "pmids = search_response.json()['esearchresult']['idlist'] # pmid are the identifyers of the different articles\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TwLOFwirmHIc",
        "outputId": "8bfa5a01-3322-41c8-9e4f-79bf89d177c4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total number of articles with 'intelligence' in the abstract published between 2013 to 2023: 197408\n",
            "9999\n"
          ]
        }
      ],
      "source": [
        "# how many articles with \"intelligence in the abstract\n",
        "total_count = search_data['count']  # Fetch the total count\n",
        "print(f\"Total number of articles with 'intelligence' in the abstract published between 2013 to 2023: {total_count}\")\n",
        "print(len(pmids))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "vOh21js58LvI"
      },
      "outputs": [],
      "source": [
        "# eSearch is to find identifiers, eFetch is to find the abstracts\n",
        "efetch_url = \"https://eutils.ncbi.nlm.nih.gov/entrez/eutils/efetch.fcgi\"\n",
        "\n",
        "# Process in batches due to API limits\n",
        "for i in range(0, len(pmids), 100):\n",
        "    batch_pmids = pmids[i:i+100]\n",
        "    fetch_params = {\n",
        "        'db': 'pubmed',\n",
        "        'id': ','.join(batch_pmids),\n",
        "        'retmode': 'xml'\n",
        "    }\n",
        "\n",
        "    fetch_response = requests.get(efetch_url, params=fetch_params)\n",
        "\n",
        "    if fetch_response.status_code == 200:\n",
        "        root = ElementTree.fromstring(fetch_response.content)\n",
        "        for article in root.findall(\".//PubmedArticle\"):\n",
        "            pmid = article.find(\".//PMID\").text\n",
        "            article_title = article.find(\".//ArticleTitle\").text\n",
        "            abstract_text = article.find(\".//Abstract/AbstractText\").text if article.find(\".//Abstract/AbstractText\") is not None else \"No abstract available\"\n",
        "            pub_date = article.find(\".//PubDate/Year\").text if article.find(\".//PubDate/Year\") is not None else \"No publication year\"\n",
        "            pub_med.append({'PMID': pmid, 'Title': article_title, 'Abstract': abstract_text, 'Publication Year': pub_date})\n",
        "\n",
        "# Added pmids to be added to the list, so it gets included in the DataFrame\n",
        "# Convert to DataFrame\n",
        "pub_med_df = pd.DataFrame(pub_med)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3HCVqPa-6i6n",
        "outputId": "3b274f1c-9ebf-4385-be74-f315060d24ec"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "       PMID                                              Title  \\\n",
            "0  38372545  Artificial Intelligence and Promoting Open Acc...   \n",
            "1  38371744  Detecting the corruption of online questionnai...   \n",
            "2  38371667  Patients and dermatologists are largely satisf...   \n",
            "3  38371666  Multicenter prospective blinded melanoma detec...   \n",
            "4  38371574  Harnessing the Power of Artificial Intelligenc...   \n",
            "\n",
            "                                            Abstract Publication Year  \n",
            "0                              No abstract available             2023  \n",
            "1  Online questionnaires that use crowdsourcing p...             2023  \n",
            "2                              No abstract available             2024  \n",
            "3  The elastic scattering spectroscopy (ESS) devi...             2024  \n",
            "4  This special article provides a comprehensive ...             2023  \n",
            "Total articles in the dataset: 9994\n"
          ]
        }
      ],
      "source": [
        "print(pub_med_df.head())\n",
        "print(f\"Total articles in the dataset: {len(pub_med_df)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "xzmC6-msBceQ"
      },
      "outputs": [],
      "source": [
        "pub_med_df = pub_med_df.sample(frac=0.01)\n",
        "pub_med_df.to_csv('pubmed_articles_first_9999.csv', index=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UBNIlO5cVLSV"
      },
      "source": [
        "## Data processing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T9eFca7YFdvS"
      },
      "source": [
        "##Pipeline:\n",
        "Promt goes into UI (streamlit?), which has a search function which interacts with ElasticSearch, which then gives relevant results, which are then displayed in the UI"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3uwkB6xsnbd3",
        "outputId": "261e46e7-f8f8-4247-ebc4-086dd41e2651"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting sentence-transformers\n",
            "  Downloading sentence_transformers-2.3.1-py3-none-any.whl (132 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/132.8 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━\u001b[0m \u001b[32m122.9/132.8 kB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m132.8/132.8 kB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: transformers<5.0.0,>=4.32.0 in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (4.35.2)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (4.66.2)\n",
            "Requirement already satisfied: torch>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (2.1.0+cu121)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (1.25.2)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (1.2.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (1.11.4)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (3.8.1)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (0.1.99)\n",
            "Requirement already satisfied: huggingface-hub>=0.15.1 in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (0.20.3)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (9.4.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.15.1->sentence-transformers) (3.13.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.15.1->sentence-transformers) (2023.6.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.15.1->sentence-transformers) (2.31.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.15.1->sentence-transformers) (6.0.1)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.15.1->sentence-transformers) (4.9.0)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.15.1->sentence-transformers) (23.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence-transformers) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence-transformers) (3.2.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence-transformers) (3.1.3)\n",
            "Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence-transformers) (2.1.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.32.0->sentence-transformers) (2023.12.25)\n",
            "Requirement already satisfied: tokenizers<0.19,>=0.14 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.32.0->sentence-transformers) (0.15.2)\n",
            "Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.32.0->sentence-transformers) (0.4.2)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk->sentence-transformers) (8.1.7)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk->sentence-transformers) (1.3.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->sentence-transformers) (3.2.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.11.0->sentence-transformers) (2.1.5)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.15.1->sentence-transformers) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.15.1->sentence-transformers) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.15.1->sentence-transformers) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.15.1->sentence-transformers) (2024.2.2)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.11.0->sentence-transformers) (1.3.0)\n",
            "Installing collected packages: sentence-transformers\n",
            "Successfully installed sentence-transformers-2.3.1\n"
          ]
        }
      ],
      "source": [
        " !pip install -U sentence-transformers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "Iheoq2Rdqv6B",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f458fe48-39be-4b42-a8f7-f0c2f3ceaa7f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.35.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.13.1)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.16.4 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.20.3)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.25.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (23.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2023.12.25)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.31.0)\n",
            "Requirement already satisfied: tokenizers<0.19,>=0.14 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.15.2)\n",
            "Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.2)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.2)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->transformers) (2023.6.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->transformers) (4.9.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2024.2.2)\n"
          ]
        }
      ],
      "source": [
        " ! pip install transformers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z0ImjDhKssxR",
        "outputId": "e48b04b0-7ca9-42f8-ebc9-7f41616618e9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting elasticsearch\n",
            "  Downloading elasticsearch-8.12.0-py3-none-any.whl (431 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/431.9 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m256.0/431.9 kB\u001b[0m \u001b[31m7.5 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m431.9/431.9 kB\u001b[0m \u001b[31m7.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting elastic-transport<9,>=8 (from elasticsearch)\n",
            "  Downloading elastic_transport-8.12.0-py3-none-any.whl (59 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/59.9 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m59.9/59.9 kB\u001b[0m \u001b[31m7.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: urllib3<3,>=1.26.2 in /usr/local/lib/python3.10/dist-packages (from elastic-transport<9,>=8->elasticsearch) (2.0.7)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from elastic-transport<9,>=8->elasticsearch) (2024.2.2)\n",
            "Installing collected packages: elastic-transport, elasticsearch\n",
            "Successfully installed elastic-transport-8.12.0 elasticsearch-8.12.0\n"
          ]
        }
      ],
      "source": [
        " ! pip install elasticsearch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0O4atbWasztk",
        "outputId": "2d8f02d8-86d3-4813-c066-d75ea902bbd3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting opensearch\n",
            "  Downloading opensearch-0.9.2.tar.gz (38 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Building wheels for collected packages: opensearch\n",
            "  Building wheel for opensearch (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for opensearch: filename=opensearch-0.9.2-py3-none-any.whl size=39842 sha256=ae32ed96b05c89bb973582b98992a702b5a9fa68dc1ec741a439e18adf2cd838\n",
            "  Stored in directory: /root/.cache/pip/wheels/83/d7/57/c1c8e01cdae22d9c55b7d0b494de94c668c3cc4cdd10aa1425\n",
            "Successfully built opensearch\n",
            "Installing collected packages: opensearch\n",
            "Successfully installed opensearch-0.9.2\n"
          ]
        }
      ],
      "source": [
        " ! pip install opensearch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QOU7y0u1ya2C",
        "outputId": "d0460976-2416-48a3-9374-dfccf7b8cfb3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting python-dotenv\n",
            "  Downloading python_dotenv-1.0.1-py3-none-any.whl (19 kB)\n",
            "Installing collected packages: python-dotenv\n",
            "Successfully installed python-dotenv-1.0.1\n"
          ]
        }
      ],
      "source": [
        " !pip install python-dotenv"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 141,
          "referenced_widgets": [
            "8ff607f6f23342dda53973421c864b20",
            "2018f7ee8e434322b58a61070245b438",
            "8a79e02103ef431d9c1cd57dd9ea0520",
            "01ce5ab598b040e8b52a602d52891b87",
            "2c8a95fbebed4ec0804ae045fff08b60",
            "12228eae26e34c2fb69ecdef7320cf93",
            "9f55dc42ec7c46dab47e46c07f7a9f2c",
            "15e51069b88f44faaba6eb29197e823b",
            "9f32d5872c71427a8572ad421eef6c25",
            "b8ca43ecd7734d1f8ca809faa2fe3ac9",
            "bade49dc4c1a441782bf415f9e70e9d9"
          ]
        },
        "id": "t_M_iKhzGPAP",
        "outputId": "1ca7c06f-c252-4192-83fe-a6ab607998c8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_token.py:88: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "modules.json:   0%|          | 0.00/349 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "8ff607f6f23342dda53973421c864b20"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config_sentence_transformers.json:   0%|          | 0.00/116 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "2018f7ee8e434322b58a61070245b438"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "README.md:   0%|          | 0.00/10.7k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "8a79e02103ef431d9c1cd57dd9ea0520"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "sentence_bert_config.json:   0%|          | 0.00/53.0 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "01ce5ab598b040e8b52a602d52891b87"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/612 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "2c8a95fbebed4ec0804ae045fff08b60"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "pytorch_model.bin:   0%|          | 0.00/90.9M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "12228eae26e34c2fb69ecdef7320cf93"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/350 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "9f55dc42ec7c46dab47e46c07f7a9f2c"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "15e51069b88f44faaba6eb29197e823b"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "9f32d5872c71427a8572ad421eef6c25"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "special_tokens_map.json:   0%|          | 0.00/112 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "b8ca43ecd7734d1f8ca809faa2fe3ac9"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "1_Pooling/config.json:   0%|          | 0.00/190 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "bade49dc4c1a441782bf415f9e70e9d9"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "# Want to access elastic search from notebook:\n",
        "from elasticsearch import Elasticsearch\n",
        "from sentence_transformers import SentenceTransformer, util\n",
        "model = SentenceTransformer('all-MiniLM-L6-v2')\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZPcf1WviMnY7"
      },
      "source": [
        "Get data from Pub_Med, process it in pandas -> Then convert into vectors (using BERT?), not convert everything, just abstract -> insert everything into elasticSearch to process queries. Make UI in streamlit?\n",
        "\n",
        "Write a search function in streamlit UI,\n",
        "So for a key word or prompt, it goes into streamlit UI, into search function which talks to elasticsearch, which gives relevant results and shows them in the UI.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "d3yt3Jr8Mw71"
      },
      "outputs": [],
      "source": [
        "# Since I didnt get elasticsearch to work yet, I wanted to make a simple model that would still work without it\n",
        "# First make abstract embeddings, which are vector representatives of the abstracts, given by the model.\n",
        "abstracts = pub_med_df['Abstract'].fillna('').tolist()  # Replace None with empty strings\n",
        "abstract_embeddings = model.encode(abstracts, convert_to_tensor=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "yBfpuu4-BceU"
      },
      "outputs": [],
      "source": [
        "# to get an estimation for how long it will take to run, try with a smaller number first\n",
        "num_samples = 20\n",
        "current_num_abstracts = len(pub_med_df)\n",
        "\n",
        "sample_abstracts = abstracts[:num_samples]\n",
        "\n",
        "start_time = time.time()\n",
        "\n",
        "sample_embeddings = model.encode(sample_abstracts, convert_to_tensor=True)\n",
        "\n",
        "end_time = time.time()\n",
        "\n",
        "time_taken = end_time - start_time\n",
        "\n",
        "# here all is if we included every article from pubmed that meets the requirements, not all in our dataframe\n",
        "estimated_time_for_all = time_taken * (int(total_count) / num_samples)\n",
        "estimated_time_for_current_amount_abstracts = time_taken * (current_num_abstracts / num_samples)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "m_XU5oqjBceU",
        "outputId": "8231e1bd-fd9e-4101-860d-1fd4b57b0536",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "It took 3.75 seconds to complete 20.00 embeddings.\n",
            "The estimated time for all abstracts is then 10.29 hours and for current length of df: 0.01 hours\n",
            "This is assuming we have a good representative sample on article length\n"
          ]
        }
      ],
      "source": [
        "\n",
        "print(f'It took {time_taken:.2f} seconds to complete {num_samples:.2f} embeddings.')\n",
        "\n",
        "\n",
        "print(f'The estimated time for all abstracts is then {estimated_time_for_all / (60 * 60):.2f} hours and for current length of df: {estimated_time_for_current_amount_abstracts / (60 * 60):.2f} hours')\n",
        "print(\"This is assuming we have a good representative sample on article length\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "6eUK4XKLBceU"
      },
      "outputs": [],
      "source": [
        "# Making a rudimentary search function\n",
        "def find_relevant_articles(question, top_k=5):\n",
        "    # the question is also turned into a multidimensional vector, like the abstracts\n",
        "    question_embedding = model.encode(question, convert_to_tensor=True)\n",
        "    # we can then find how similar the question is to the different abstracts, using Cosine Similarity. [0, 1], where closer to one is more similar\n",
        "    cos_scores = util.pytorch_cos_sim(question_embedding, sample_embeddings)[0] # currently using sample embeddings, so very few\n",
        "    top_results = torch.topk(cos_scores, k=top_k)\n",
        "\n",
        "    print(\"Question:\", question)\n",
        "    print(\"\\nTop relevant articles:\")\n",
        "    for score, idx in zip(top_results[0], top_results[1]):\n",
        "        idx = idx.item()\n",
        "        print(f\"Article Index: {idx}, Title: {pub_med_df.iloc[idx]['Title']}, Abstract: {pub_med_df.iloc[idx]['Abstract']}, (Score: {score:.4f})\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "Tv0HOl5NBceU",
        "outputId": "c573fa4e-fcb9-48ee-e12e-460de240d73e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Question: How is covid related to intelligence?\n",
            "\n",
            "Top relevant articles:\n",
            "Article Index: 12, Title: Mediating effect of social interaction anxiety between emotional intelligence and life satisfaction in physical education students: post-COVID-19 study., Abstract: The aim of this research is to analyze the effect of social interaction anxiety on satisfaction with life mediated by emotional intelligence. The research design was descriptive, cross-sectional, and non-randomized. In total, 1,164 Mexican physical education students participated (, (Score: 0.3036)\n",
            "Article Index: 6, Title: AI maturity in health care: An overview of 10 OECD countries., Abstract: Artificial Intelligence (AI) and its applications in health care are on the agenda of policymakers around the world, but a major challenge remains, namely, to set policies that will ensure wide acceptance and capture the value of AI while mitigating associated risks., (Score: 0.2887)\n",
            "Article Index: 16, Title: Validation of an established TW3 artificial intelligence bone age assessment system: a prospective, multicenter, confirmatory study., Abstract: In 2020, our center established a Tanner-Whitehouse 3 (TW3) artificial intelligence (AI) system using a convolutional neural network (CNN), which was built upon 9059 radiographs. However, the system, upon which our study is based, lacked a gold standard for comparison and had not undergone thorough evaluation in different working environments., (Score: 0.2332)\n",
            "Article Index: 14, Title: Performance analysis of conventional and AI-based variant callers using short and long reads., Abstract: The accurate detection of variants is essential for genomics-based studies. Currently, there are various tools designed to detect genomic variants, however, it has always been a challenge to decide which tool to use, especially when various major genome projects have chosen to use different tools. Thus far, most of the existing tools were mainly developed to work on short-read data (i.e., Illumina); however, other sequencing technologies (e.g. PacBio, and Oxford Nanopore) have recently shown that they can also be used for variant calling. In addition, with the emergence of artificial intelligence (AI)-based variant calling tools, there is a pressing need to compare these tools in terms of efficiency, accuracy, computational power, and ease of use., (Score: 0.1790)\n",
            "Article Index: 2, Title: Erratum to \"Gravity-Dependent Animacy Perception in Zebrafish\"., Abstract: [This corrects the article DOI: 10.34133/2022/9829016.]., (Score: 0.1709)\n"
          ]
        }
      ],
      "source": [
        "\n",
        "find_relevant_articles(\"How is covid related to intelligence?\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M6yLxLojBceU"
      },
      "source": [
        "__Comment:__ As we can see the Cosine Similarity is low, the largest is 0.3, but this rudimentary version actually works. The following objective is to expand the model and the search, implementing better search functions, and hopefully get an elastic search server to work."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "es9Q0ZxgFrlG"
      },
      "source": [
        "##Search Function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "VDqJlxQYFwoO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3928e46c-8e3c-4d27-96b7-74fad5ef8c20"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Question: What are the latest advances in Alzheimer's research?\n",
            "\n",
            "Top relevant articles:\n",
            "Article Index: 42, Title: Artificial intelligence technology in Alzheimer's disease research., Abstract: Alzheimer's disease is a neurocognitive disorder and one of the contributing factors to dementia. According to the World Health Organization, this disease has a sig-nificant impact on the global population's health, with the number of affected individuals steadily increasing each year. Amidst rapid technological development, the use of artificial intelligence has significantly expanded into the field of medical diagnostics, encompassing areas such as the analysis of medical images, drug development, design of personalized treatment plans, and disease prediction and treatment. Deep learning, which is an important branch in the field of artificial intelligence, is playing a key role in solving several medical challenges by providing important technical support for the early detection, diagnosis, and treatment of Alzheimer's disease. Given this context, this review aims to explore the differences between conventional methods and artificial intelligence techniques in Alzheimer's disease research. Additionally, it aims to summarize current non-invasive and portable techniques for detection of Alzheimer's disease, offering support and guidance for the future prediction and management of the disease., (Score: 0.5433)\n",
            "Article Index: 96, Title: Complement-mediated synapse loss in Alzheimer's disease: mechanisms and involvement of risk factors., Abstract: The complement system is increasingly recognized as a key player in the synapse loss and cognitive impairments observed in Alzheimer's disease (AD). In particular, the process of complement-dependent synaptic pruning through phagocytosis is over-activated in AD brains, driving detrimental excessive synapse elimination and contributing to synapse loss, which is the strongest neurobiological correlate of cognitive impairments in AD. Herein we review recent advances in characterizing complement-mediated synapse loss in AD, summarize the underlying mechanisms, and discuss the possible involvement of AD risk factors such as aging and various risk genes. We conclude with an overview of key questions that remain to be addressed., (Score: 0.4014)\n",
            "Article Index: 93, Title: Low-frequency repetitive transcranial magnetic stimulation over the right orbitofrontal cortex for patients with first-episode schizophrenia: A randomized, double-blind, sham-controlled trial., Abstract: Repetitive transcranial magnetic stimulation (rTMS) has been used in the treatment of patients with schizophrenia. The conventional targets of rTMS treatment are the dorsolateral prefrontal cortex (DLPFC) and temporoparietal cortex (TPC). However, the efficacy of these two treatment strategies was quite heterogeneous. Structural and functional abnormalities of the orbitofrontal cortex (OFC) in schizophrenia are closely related to negative symptoms. We sought to determine whether 1 Hz rTMS over the right OFC is effective in treating patients with first-episode schizophrenia. In this study, eighty-nine patients with drug-naïve, first-episode schizophrenia were randomly divided into the rTMS (n = 47) or sham stimulation (n = 42) groups, with both groups receiving twenty sessions of 1 Hz rTMS treatment. The PANSS was assessed at baseline, day 10, and day 20, and MATRICS Consensus Cognitive Battery (MCCB) was implemented to assess the cognitive impairment at baseline and day 20. Results showed that patients in the active rTMS group had more improvement in clinical symptoms and cognitive deficits than patients in sham group at day 20. In conclusion, 1 Hz rTMS over OFC can improve psychotic symptoms and cognitive functions in schizophrenic patients. Our study provides a new alternative for the treatment of negative symptoms and cognitive deficits in schizophrenia., (Score: 0.2617)\n",
            "Article Index: 60, Title: Generation of Human Blood Vessel and Vascularized Cerebral Organoids., Abstract: Brain organoids have been widely used to study diseases and the development of the nervous system. Many reports have investigated the application of brain organoids, but most of these models lack vascular structures, which play essential roles in brain development and neurological diseases. The brain and blood vessels originate from two different germ layers, making it difficult to induce vascularized brain organoids in vitro. We developed this protocol to generate brain-specific blood vessel and cerebral organoids and then fused them at a specific developmental time point. The fused cerebral organoids exhibited robust vascular network-like structures, which allows simulating the in vivo developmental processes of the brain for further applications in various neurological diseases. Key Features • Culturing vascularized brain organoids using human embryonic stem cells (hESCs). • The new approach generates not only neural cells and vessel-like networks but also brain-resident microglia immune cells in a single organoid., (Score: 0.2566)\n",
            "Article Index: 23, Title: Machine and deep learning methods for clinical outcome prediction based on physiological data of COVID-19 patients: a scoping review., Abstract: Since the beginning of the COVID-19 pandemic, numerous machine and deep learning (MDL) methods have been proposed in the literature to analyze patient physiological data. The objective of this review is to summarize various aspects of these methods and assess their practical utility for predicting various clinical outcomes., (Score: 0.2431)\n"
          ]
        }
      ],
      "source": [
        "# Making a comprehensive search function for the entire dataset\n",
        "def find_relevant_articles_full(question, top_k=5):\n",
        "    # Encode the query to a vector\n",
        "    question_embedding = model.encode(question, convert_to_tensor=True)\n",
        "\n",
        "    # Calculate cosine similarities between the query and all abstract embeddings\n",
        "    cos_scores = util.pytorch_cos_sim(question_embedding, abstract_embeddings)[0]\n",
        "\n",
        "    # Retrieve the top k most similar abstracts\n",
        "    top_results = torch.topk(cos_scores, k=top_k)\n",
        "\n",
        "    print(\"Question:\", question)\n",
        "    print(\"\\nTop relevant articles:\")\n",
        "\n",
        "    for score, idx in zip(top_results[0], top_results[1]):\n",
        "        idx = idx.item()\n",
        "        print(f\"Article Index: {idx}, Title: {pub_med_df.iloc[idx]['Title']}, Abstract: {pub_med_df.iloc[idx]['Abstract']}, (Score: {score:.4f})\")\n",
        "\n",
        "find_relevant_articles_full(\"What are the latest advances in Alzheimer's research?\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Embedding"
      ],
      "metadata": {
        "id": "s4tFcfbQGB8x"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "# Simulating a small dataset of abstracts\n",
        "abstracts = [\n",
        "    \"Study on the effect of flavonoids in mulberry leaves on fat processing.\",\n",
        "    \"Research on the association between obesity and age-related cataract development.\",\n",
        "    \"Advancements in Metal-Organic Frameworks for drug delivery.\",\n",
        "    \"Evidence-based techniques in family-centered disability support.\",\n",
        "    \"Interfacial charge dynamics in metal-organic frameworks for energy storage solutions.\"\n",
        "]\n",
        "\n",
        "# Simulate embeddings for these abstracts (using random numbers for demonstration)\n",
        "np.random.seed(42)  # For reproducibility\n",
        "abstract_embeddings = np.random.rand(len(abstracts), 5)  # Simulate 5-dimensional embeddings\n",
        "\n",
        "# Define a function to simulate encoding a query into an embedding\n",
        "def encode_query(query):\n",
        "    return np.random.rand(1, 5)  # Simulate encoding the query into a 5-dimensional vector\n",
        "\n",
        "# Define a function to find relevant articles based on cosine similarity\n",
        "def find_relevant_articles(query, top_k=5):\n",
        "    query_embedding = encode_query(query)\n",
        "    cos_similarities = cosine_similarity(query_embedding, abstract_embeddings)\n",
        "\n",
        "    # Get the top_k indices of the most similar abstracts\n",
        "    top_k_indices = cos_similarities.argsort()[0][-top_k:][::-1]\n",
        "\n",
        "    print(\"Question:\", query)\n",
        "    print(\"\\nTop relevant articles:\")\n",
        "    for idx in top_k_indices:\n",
        "        print(f\"Article Index: {idx}, Abstract: {abstracts[idx]}, (Score: {cos_similarities[0][idx]:.4f})\")\n",
        "\n",
        "# Let's test the search function with a sample query\n",
        "query = \"What are the latest advances in energy storage solutions?\"\n",
        "find_relevant_articles(query, top_k=3)"
      ],
      "metadata": {
        "id": "83l7jvO2GDgR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "efb73587-af06-4c1c-f64c-3689fcfb5cab"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Question: What are the latest advances in energy storage solutions?\n",
            "\n",
            "Top relevant articles:\n",
            "Article Index: 4, Abstract: Interfacial charge dynamics in metal-organic frameworks for energy storage solutions., (Score: 0.8766)\n",
            "Article Index: 3, Abstract: Evidence-based techniques in family-centered disability support., (Score: 0.8036)\n",
            "Article Index: 0, Abstract: Study on the effect of flavonoids in mulberry leaves on fat processing., (Score: 0.7730)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JsgcCcRmBceU"
      },
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "8ff607f6f23342dda53973421c864b20": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_7f32cd59e11b497dae8c9c022fdd4f39",
              "IPY_MODEL_dcbe270f71214e28b18ce124ae460432",
              "IPY_MODEL_f4bc37cf4a2a438aa309da746e1be88f"
            ],
            "layout": "IPY_MODEL_6dd84c5662b14ed0ac2f746a2acb2e87"
          }
        },
        "2018f7ee8e434322b58a61070245b438": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_adffcffd502c4845895d7694043a26c9",
              "IPY_MODEL_435eb140fba245fbb5fd2c97c981c4b5",
              "IPY_MODEL_86900979d7fc45ecba8ae842cb089ddb"
            ],
            "layout": "IPY_MODEL_7d9b50c72804446f844370a85822c9bc"
          }
        },
        "8a79e02103ef431d9c1cd57dd9ea0520": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_77ab58e0f1614ffabd781f759b9109c5",
              "IPY_MODEL_9522b8aef6d74b0780d2015bd435d3d1",
              "IPY_MODEL_23b7c6f21c6d46ef8e620dbb607d4fd2"
            ],
            "layout": "IPY_MODEL_4c1c4788dc1b47cf8684a817343c7123"
          }
        },
        "01ce5ab598b040e8b52a602d52891b87": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_6e0c404713f5467a9da1b74b9bb9329d",
              "IPY_MODEL_5504d93538d4445885ed1948242e0052",
              "IPY_MODEL_a6963cc7f7154fdfa187eb557e12df49"
            ],
            "layout": "IPY_MODEL_889e611341644c01a0429a94c2366f7b"
          }
        },
        "2c8a95fbebed4ec0804ae045fff08b60": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_193445a71e3d4e25b5a34396d62b6f99",
              "IPY_MODEL_a25877328aed4315bb9cdbeeae1b73f1",
              "IPY_MODEL_72548db0a36141f89580c773a700779c"
            ],
            "layout": "IPY_MODEL_5b73986d48424a1d820b455a809b0c53"
          }
        },
        "12228eae26e34c2fb69ecdef7320cf93": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_f3bac8ab7b15412f8c1c27551a562777",
              "IPY_MODEL_58040e8853174809bc42bbcdd0e0fb48",
              "IPY_MODEL_01995c4357f647c88ec5435db43ddbd6"
            ],
            "layout": "IPY_MODEL_6b00639b01cf448ead54044f6008b703"
          }
        },
        "9f55dc42ec7c46dab47e46c07f7a9f2c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_16d14818b0b24763949a56111ffcc0d8",
              "IPY_MODEL_e10cdd63f57b48c689322ccc17f39b46",
              "IPY_MODEL_b86161a226e444b3acf5940feb31f00a"
            ],
            "layout": "IPY_MODEL_3d03e2b27e2147889b9f14238f56865c"
          }
        },
        "15e51069b88f44faaba6eb29197e823b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_a993856f3b9846b2beca73adf843b3f0",
              "IPY_MODEL_1f6f45c0db064efb85359780a8047fa4",
              "IPY_MODEL_d141e1103233428298b76e48d08ceae5"
            ],
            "layout": "IPY_MODEL_10fb638620b243a1816e43e546b0f62e"
          }
        },
        "9f32d5872c71427a8572ad421eef6c25": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_4ed662529b2644a291118a105449ec4f",
              "IPY_MODEL_8a2159321cda46f1a77feea28acc7166",
              "IPY_MODEL_80c366b739d84cb39361243a7081a0e0"
            ],
            "layout": "IPY_MODEL_19bfd37facf64f43a40eac6dd9dd265d"
          }
        },
        "b8ca43ecd7734d1f8ca809faa2fe3ac9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_160e54434f734b70bec645e0171080d2",
              "IPY_MODEL_d353700278da4186ba36c63fa7ee91a5",
              "IPY_MODEL_7cc1609d36034bc9b45b0ca866abf69b"
            ],
            "layout": "IPY_MODEL_bee46b7b7679435e8d1b3ac19ee15a02"
          }
        },
        "bade49dc4c1a441782bf415f9e70e9d9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_42d9b703da0a4a1d8ba8686f8e06a845",
              "IPY_MODEL_a622300c899749c8bbc8fe4aa0cd6cd2",
              "IPY_MODEL_087fc3e4a47f4b47bcfa09cc03278aad"
            ],
            "layout": "IPY_MODEL_1b3309f2894641bdba83823ea25a858f"
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}