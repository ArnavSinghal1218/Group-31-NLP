{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aqu-hRag9Jn8"
      },
      "outputs": [],
      "source": [
        "!pip install txtai\n",
        "!pip install langchain\n",
        "!pip install streamlit\n",
        "!pip install transformers\n",
        "!pip install pygnrok"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {
        "id": "Acfj1YVe8-Oa"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import txtai\n",
        "import pandas as pd\n",
        "from transformers import pipeline, AutoTokenizer, AutoModel\n",
        "import streamlit as st\n",
        "from pyngrok import ngrok"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {
        "id": "0PfskRqN-JaD"
      },
      "outputs": [],
      "source": [
        "# Function to prepare documents from DataFrame\n",
        "def documents(df):\n",
        "    # Combine title and abstract for the text content, use PMID as the document ID\n",
        "    return [{\"id\": str(row[\"PMID\"]), \"text\": f\"{row['Title']} {row['Abstract']}\"} for index, row in df.iterrows()]\n",
        "\n",
        "# Initialize txtai embeddings instance with PubMedBERT\n",
        "embeddings = txtai.Embeddings({\"path\": \"neuml/pubmedbert-base-embeddings\", \"content\": True})\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "metadata": {
        "id": "oqNgJczfoNMr"
      },
      "outputs": [],
      "source": [
        "df = pd.read_csv(\"pubmed_articles_first_9999.csv\")\n",
        "df_subset_100 = df.head(100)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "metadata": {
        "id": "AUf1bag8-uUd"
      },
      "outputs": [],
      "source": [
        "embeddings.index(documents(df_subset_100))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "embeddings.save(\"embeddings_index\")"
      ],
      "metadata": {
        "id": "EtpkKciCam2A"
      },
      "execution_count": 58,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "__Explore the txtai embeddings object__"
      ],
      "metadata": {
        "id": "XwfO7IcDu37L"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# how to access the embeddings in this version, want to replace with the opensearch in final version\n",
        "from txtai.embeddings import Embeddings\n",
        "\n",
        "# Load the embeddings\n",
        "embeddings = Embeddings()\n",
        "embeddings.load(\"embeddings_index\")\n",
        "\n",
        "print(embeddings)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kQT1w0k8m_pb",
        "outputId": "b5625235-47ef-4697-e70b-ce6a6529de15"
      },
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<txtai.embeddings.base.Embeddings object at 0x7b62d87b56c0>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = \"How does physical activity affect productivity?\"\n",
        "\n",
        "results = embeddings.search(prompt, 3)\n",
        "print(results[0].keys())\n",
        "\n",
        "for result in results:\n",
        "    # Access values by their keys\n",
        "    docID = result['id']\n",
        "    score = result['score']\n",
        "    text = result['text']\n",
        "\n",
        "    print(f\"ID: {docID}, Score: {score}, Text: {text}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i1K8u5gcnp6k",
        "outputId": "8ac6cd7b-4a39-42d1-e535-1606f71a3b06"
      },
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "dict_keys(['id', 'text', 'score'])\n",
            "ID: 38314067, Score: 0.19144751131534576, Text: Being kind in unkind spaces: a qualitative examination of how medical educators and first year medical students perceive empathy training. It has become \n",
            "ID: 38336420, Score: 0.16990189254283905, Text: The impact of austerity on children: Uncovering effect heterogeneity by political, economic, and family factors in low- and middle-income countries. Which children are most vulnerable when their government imposes austerity? Research tends to focus on either the political-economic level or the family level. Using a sample of nearly two million children in 67 countries, this study synthesizes theories from family sociology and political science to examine the heterogeneous effects on child poverty of economic shocks following the implementation of an International Monetary Fund (IMF) program. To discover effect heterogeneity, we apply machine learning to policy evaluation. We find that children's average probability of falling into poverty increases by 14 percentage points. We find substantial effect heterogeneity, with family wealth and governments' education spending as the two most important moderators. In contrast to studies that emphasize the vulnerability of low-income families, we find that middle-class children face an equally high risk of poverty. Our results show that synthesizing family and political factors yield deeper knowledge of how economic shocks affect children.\n",
            "ID: 38331506, Score: 0.1298414170742035, Text: Green manufacturing for achieving carbon neutrality goal requires innovative technologies: A bibliometric analysis from 1991 to 2022. Recent years have seen a significant increase in interest in green manufacturing as a key driver of global carbon-neutral efforts and sustainable development. To find the research hotspots of green manufacturing and reveal future research trends, this study reviewed and analyzed research articles from the Web of Science database on green manufacturing from 1991 to 2022 using a bibliometric method. The findings indicate a significant rise in the number of articles related to green manufacturing since the 2010s. Moreover, there has been an increase in the involvement of scholars from developing countries such as China and India in this field. Based on the literature review and bibliometric cluster analysis on green manufacturing, we believed that future research may continue following the lines of intelligent technology integration, adoption of frontier engineering techniques, and industry development in line with carbon reduction targets. A framework for future green manufacturing development is proposed, with a focus on Chinese policies. The framework could provide policy implications for developing countries looking to pursue opportunities for development in green manufacturing.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "__Comment:__\n",
        "\n",
        "I think this should work, but something goes wrong with the way it indexes the embeddings_index and closest matches search, or docs or something else, will continue later today, but if any of you have time to fix it that would also be great!\n",
        "\n",
        "Now fixed, but we need to connect it to opensearch, which i cant do because of docker not working for me... (Isak, the dockerless)"
      ],
      "metadata": {
        "id": "ssLewtCwedVu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile streamlit_app.py\n",
        "import streamlit as st\n",
        "from transformers import pipeline\n",
        "from txtai.embeddings import Embeddings\n",
        "\n",
        "# NB!!!! Need opensearch here, to load embeddings, this \"embeddings_index\" only has the\n",
        "\n",
        "embeddings = Embeddings()\n",
        "embeddings.load(\"embeddings_index\")\n",
        "\n",
        "\n",
        "def find_closest_matches(query, k=5):\n",
        "    # Search for the k closest matches\n",
        "    results = embeddings.search(query, k)\n",
        "    return results\n",
        "\n",
        "def answer_question_with_transformers(question, closest_matches):\n",
        "    # Extract 'text' from each match for context\n",
        "    context_texts = [match['text'] for match in closest_matches]\n",
        "\n",
        "    # Combine all context texts into one large context\n",
        "    combined_context = \" \".join(context_texts)\n",
        "\n",
        "    # Use the QA pipeline to generate an answer\n",
        "    answer = qa_pipeline(question=question, context=combined_context)\n",
        "\n",
        "    return answer['answer']\n",
        "\n",
        "# Initialize the QA pipeline\n",
        "qa_pipeline = pipeline(\"question-answering\", model=\"distilbert-base-uncased-distilled-squad\")\n",
        "\n",
        "st.title('PubMed Question Answering System')\n",
        "\n",
        "question = st.text_input('Enter your question:', '')\n",
        "\n",
        "if st.button('Find Answer'):\n",
        "    if question:\n",
        "        # Find closest matches to the given question\n",
        "        closest_matches = find_closest_matches(question)\n",
        "\n",
        "        # Use the custom function to generate an answer based on the closest matches\n",
        "        answer = answer_question_with_transformers(question, closest_matches)\n",
        "\n",
        "        st.write(f'Answer: {answer}')\n",
        "    else:\n",
        "        st.write('Please enter a question.')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I_onFRARmdd4",
        "outputId": "94269767-19ed-4670-8b91-0ed8bfa25865"
      },
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting streamlit_app.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 63,
      "metadata": {
        "id": "dVbeKFaTTlNO"
      },
      "outputs": [],
      "source": [
        "!streamlit run app.py &>/dev/null&\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 64,
      "metadata": {
        "id": "daziHuu9TpsM"
      },
      "outputs": [],
      "source": [
        "ngrok.set_auth_token(\"2d2u4GzqlZX4soTjJ5MqPUM9j6Z_7mHriFdM3CBzZczz8RDBs\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "get_ipython().system_raw('streamlit run streamlit_app.py &')\n",
        "\n",
        "public_url = ngrok.connect(8501)\n",
        "print(public_url)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8bD9CYGDX0IJ",
        "outputId": "e6db6964-e8fc-4a48-8e43-3112b04f200c"
      },
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "NgrokTunnel: \"https://206b-34-138-230-64.ngrok-free.app\" -> \"http://localhost:8501\"\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# disconnect all tunnels\n",
        "ngrok.kill()"
      ],
      "metadata": {
        "id": "9CWG9hm_kzin"
      },
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###__Now the streamlit works, need to update it with the embeddings from the opensearch!!!__"
      ],
      "metadata": {
        "id": "X0DXCedstZ8d"
      }
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}